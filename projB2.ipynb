{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"projB2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project B2: Spam/Ham Classification - Build Your Own Model\n",
    "\n",
    "## Feature Engineering, Classification, and Cross-Validation\n",
    "## Due Date: Thursday, December 5th, 11:59 PM PDT\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline, Thursday, December 5th, 11:59 PM PDT. Please read the syllabus for the Slip Day policy. No late submissions beyond what is outlined in the Slip Day policy will be accepted. We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline. This way, you will have ample time to reach out to staff for support if you encounter difficulties with submission. While course staff is happy to help guide you with submitting your assignment ahead of the deadline, we will not respond to last-minute requests for assistance (TAs need to sleep, after all!).\n",
    "\n",
    "Please read the instructions carefully when submitting your work to Gradescope. \n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the project, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** in the collaborators cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "proj2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "In this project, you will build and improve on the concepts and functions you implemented in Project B1 to create your own classifier to distinguish spam emails from ham (non-spam) emails. We will evaluate your work based on your model's accuracy and written responses in this notebook.\n",
    "\n",
    "After this assignment, you should feel comfortable with the following:\n",
    "\n",
    "- Using `sklearn` libraries to process data and fit classification models.\n",
    "- Validating the performance of your model and minimizing overfitting.\n",
    "- Generating and analyzing ROC curves.\n",
    "\n",
    "## Content Warning\n",
    "This is a **real-world** dataset —— the emails you are trying to classify are actual spam and legitimate emails. As a result, some of the spam emails may be in poor taste or be considered inappropriate. We think the benefit of working with realistic data outweighs these inappropriate emails, but we wanted to warn you at the beginning of the project so that you are made aware.\n",
    "\n",
    "If you feel uncomfortable with this topic, **please contact your TA, the instructors, or reach out via the [Fall 2024 additional accommodations form](https://docs.google.com/forms/d/e/1FAIpQLScwnGIQjfqWzH2Acx5bEBNZzNeLAdI1_MfR34zPLZl7ezYIoA/viewform).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all FutureWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "Grading is broken down into autograded answers and free responses. \n",
    "\n",
    "For autograded answers, the results of your code are compared to provided and/or hidden tests.\n",
    "\n",
    "For free response questions, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question.\n",
    "\n",
    "Question | Manual | Points\n",
    "----|----|----\n",
    "1a | Yes | 4\n",
    "1b | Yes | 2\n",
    "2 | No | 0\n",
    "3a | No | 5\n",
    "3b | No | 10\n",
    "4 | Yes | 6\n",
    "5 | Yes | 3\n",
    "6a | Yes | 3\n",
    "6b | Yes | 2\n",
    "7ai | No | 1\n",
    "7aii | Yes | 1\n",
    "7bi | Yes | 1\n",
    "7bii | Yes | 1\n",
    "7c | Yes | 1\n",
    "7d | Yes | 2\n",
    "7e | Yes | 2\n",
    "Total | 12 | 44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Start\n",
    "\n",
    "For each question in the assignment, please write down your answer in the answer cell(s) right below the question. \n",
    "\n",
    "We understand that it is helpful to have extra cells breaking down the process of reaching your final answer. If you happen to create new cells below your answer to run code, **NEVER** add cells between a question cell and the answer cell below it. It will cause errors when we run the autograder, and it will sometimes cause a failure to generate the PDF file.\n",
    "\n",
    "**Important note: The local autograder tests will not be comprehensive. You can pass the automated tests in your notebook but still fail tests in the autograder.** Please be sure to check your results carefully.\n",
    "\n",
    "### Debugging Guide\n",
    "If you run into any technical issues, we highly recommend checking out the [Data 100 Debugging Guide](https://ds100.org/debugging-guide/). This guide contains general questions about Jupyter notebooks / Datahub, Gradescope, common `pandas` errors, RegEx, visualizations, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:41.341673Z",
     "start_time": "2019-04-03T20:17:41.330307Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Setup and Recap\n",
    "\n",
    "Here, we will provide a summary of Project B1 to remind you of how we cleaned the data, explored it, and implemented methods helpful in building your own model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Loading and Cleaning Data\n",
    "\n",
    "Remember that in the email classification task, our goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email. \n",
    "\n",
    "The dataset consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8,348 labeled examples, and the unlabeled test set contains 1,000 unlabeled examples.\n",
    "\n",
    "Run the following cell to load the data into a `DataFrame`.\n",
    "\n",
    "The `train` `DataFrame` contains labeled data that you will use to train your model. It contains four columns:\n",
    "\n",
    "1. `id`: An identifier for the training example.\n",
    "1. `subject`: The subject of the email.\n",
    "1. `email`: The text of the email.\n",
    "1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam).\n",
    "\n",
    "The `test` `DataFrame` contains 1,000 unlabeled emails. You will predict labels for these emails and submit your predictions to the autograder for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('spam_ham_data.zip') as item:\n",
    "    with item.open(\"train.csv\") as f:\n",
    "        original_training_data = pd.read_csv(f)\n",
    "    with item.open(\"test.csv\") as f:\n",
    "        test = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: A&amp;L Daily to be auctioned in bankrupt...</td>\n",
       "      <td>url: http://boingboing.net/#85534171\\n date: n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: Wired: \"Stronger ties between ISPs an...</td>\n",
       "      <td>url: http://scriptingnews.userland.com/backiss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: It's just too small                  ...</td>\n",
       "      <td>&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n &lt;font siz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: liberal defnitions\\n</td>\n",
       "      <td>depends on how much over spending vs. how much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: RE: [ILUG] Newbie seeks advice - Suse...</td>\n",
       "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  Subject: A&L Daily to be auctioned in bankrupt...   \n",
       "1   1  Subject: Wired: \"Stronger ties between ISPs an...   \n",
       "2   2  Subject: It's just too small                  ...   \n",
       "3   3                      Subject: liberal defnitions\\n   \n",
       "4   4  Subject: RE: [ILUG] Newbie seeks advice - Suse...   \n",
       "\n",
       "                                               email  spam  \n",
       "0  url: http://boingboing.net/#85534171\\n date: n...     0  \n",
       "1  url: http://scriptingnews.userland.com/backiss...     0  \n",
       "2  <html>\\n <head>\\n </head>\\n <body>\\n <font siz...     1  \n",
       "3  depends on how much over spending vs. how much...     0  \n",
       "4  hehe sorry but if you hit caps lock twice the ...     0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the emails to lowercase as the first step of text processing.\n",
    "original_training_data['email'] = original_training_data['email'].str.lower()\n",
    "test['email'] = test['email'].str.lower()\n",
    "\n",
    "original_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore the dataset above along with any specific spam and ham emails that interest you. Keep in mind that our data may contain missing values, which are handled in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.203231Z",
     "start_time": "2019-04-03T20:17:42.185104Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1fb39d9b651ca1b",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before imputation:\n",
      "id         0\n",
      "subject    6\n",
      "email      0\n",
      "spam       0\n",
      "dtype: int64\n",
      "------------\n",
      "After imputation:\n",
      "id         0\n",
      "subject    0\n",
      "email      0\n",
      "spam       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill any missing or NAN values.\n",
    "print('Before imputation:')\n",
    "print(original_training_data.isnull().sum())\n",
    "original_training_data = original_training_data.fillna('')\n",
    "print('------------')\n",
    "print('After imputation:')\n",
    "print(original_training_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Validation Split\n",
    "\n",
    "Recall that the training data we downloaded is all the data we have available for both training models and **validating** the models that we train. Therefore, we split the training data into separate training and validation datasets. Once you have finished training, you will need this validation data to assess the performance of your classifier. \n",
    "\n",
    "As in Project B1, we set the seed (`random_state`) to 42. **Do not modify this in the following questions, as our tests depend on this random seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.317970Z",
     "start_time": "2019-04-03T20:17:42.294532Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-873194ed3e686dfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This creates a 90/10 train-validation split on our labeled data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(original_training_data, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# We must do this in order to preserve the ordering of emails to labels for words_in_texts.\n",
    "train = train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "feat-eng",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We need a numeric feature matrix $\\mathbb{X}$ and a vector of corresponding binary labels $\\mathbb{Y}$ to train a logistic regression model. In Project B1, we implemented the function `words_in_texts`, which creates numeric features derived from the email text and uses those features for logistic regression. \n",
    "\n",
    "For this project, we have provided you with an implemented version of `words_in_texts`. Remember that the function outputs a 2-dimensional `NumPy` array containing one row for each email text. The row should contain a 0 or a 1 for each word in the list: 0 if the word doesn't appear in the text and 1 if the word does. \n",
    "\n",
    "Run the following cell to see how the function works on some text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from projB2_utils import words_in_texts\n",
    "\n",
    "words_in_texts(['hello', 'bye', 'world'], pd.Series(['hello', 'hello worldhello']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "classification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## EDA and Basic Classification\n",
    "\n",
    "In Project B1, we visualized the frequency of different words in spam and ham emails and used `words_in_texts(words, train['email'])` to train a classifier directly. We also provided a simple set of 5 words that might be useful as features to distinguish spam/ham emails. \n",
    "\n",
    "We then built a model using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier from `sklearn`.\n",
    "\n",
    "Run the following cell to see the performance of a simple model using these words and the `train` `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.726012Z",
     "start_time": "2019-04-03T20:17:43.498088Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q4-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = words_in_texts(some_words, train['email'])\n",
    "Y_train = np.array(train['spam'])\n",
    "\n",
    "X_train[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:44.593918Z",
     "start_time": "2019-04-03T20:17:43.783872Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q5-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7576201251164648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "simple_model = LogisticRegression()\n",
    "simple_model.fit(X_train, Y_train)\n",
    "\n",
    "training_accuracy = simple_model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our models, we evaluate the accuracy of the training set, which may provide a misleading accuracy measure. In Project B1, we calculated various metrics to consider other ways of evaluating a classifier, in addition to overall accuracy. Below is a reference to those concepts.\n",
    "\n",
    "Presumably, our classifier will be used for **filtering**, or preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
    "- **False positive (FP)**: A ham email gets flagged as spam and filtered out of the inbox.\n",
    "- **False negative (FN)**: A spam email gets mislabeled as ham and ends up in the inbox.\n",
    "\n",
    "To be clear, we label spam emails as 1 and ham emails as 0. These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier in addition to overall accuracy:\n",
    "\n",
    "**Precision**: Measures the proportion of emails flagged as spam that are actually spam. Mathematically, $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$.\n",
    "\n",
    "**Recall**: Measures the proportion  of spam emails that were correctly flagged as spam. Mathematically, $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$.\n",
    "\n",
    "**False positive rate**: Measures the proportion  of ham emails that were incorrectly flagged as spam. Mathematically, $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$.\n",
    "\n",
    "The below graphic (modified slightly from [Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall)) may help you understand precision and recall visually:<br />\n",
    "<center>\n",
    "<img alt=\"precision_recall\" src=\"precision_recall.png\" width=\"600px;\" />\n",
    "</center>\n",
    "\n",
    "Note that a True Positive (TP) is a spam email that is classified as spam, and a True Negative (TN) is a ham email that is classified as ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Moving Forward\n",
    "\n",
    "With this in mind, it is now your task to make the spam filter more accurate. To get full credit on the accuracy part of this assignment, you must get at least **85%** accuracy on both the train and test set (see Question 3 for the partial credit breakdown). To determine your accuracy on the test set, you will use your classifier to predict every email in the `test` `DataFrame` and upload your predictions to Gradescope.\n",
    "\n",
    "**You will only be able to submit your test set predictions to Gradescope up to 4 times per day**. You will be able to see your accuracy on the entire test set when submitting to Gradescope. Note that attempts will not carry over across days, so we recommend planning ahead to make sure you have enough time to finetune your model! In the case that you are approved for an extension, you are granted 4 more submissions for each day the deadline has been extended.\n",
    "\n",
    "Here are some ideas for improving your model:\n",
    "\n",
    "1. Finding better features based on the email text. Some example features are:\n",
    "    1. Number of characters in the subject/body\n",
    "    1. Number of words in the subject/body\n",
    "    1. Use of punctuation (e.g., how many '!'s were there?)\n",
    "    1. Number/percentage of capital letters \n",
    "    1. Whether the email is a reply to an earlier email or a forwarded email\n",
    "1. Finding better words to use as features. Which words are the best at distinguishing emails? This requires digging into the email text itself. Alternatively, you can identify misclassified emails and see which relevant words are missing in your model.\n",
    "1. Reducing dimensionality and/or multicollinearity. There are a few methods to achieve this:\n",
    "    1. Interpret the model coefficients. Note that a feature will be more valuable in classification if its coefficient has a larger **absolute** value. If the coefficient has a lower **absolute** value, the feature likely isn't valuable in classifying emails.\n",
    "1. Better data processing. For example, many emails contain HTML as well as text. You can consider extracting the text from the HTML to help you find better words. Or, you can match HTML tags themselves, or even some combination of the two.\n",
    "1. Model selection. You can adjust the parameters of your model (e.g. the penalty type, the regularization parameter, or any arguments in `LogisticRegression`) to achieve higher accuracy. Recall that you should use cross-validation for feature and model selection! Otherwise, you will likely overfit to your training data.\n",
    "    1. Consider implementing L1 regularization. The [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for `LogisticRegression` may be helpful here. \n",
    "    1. We have imported `GridSearchCV` for you. You may use sklearn's `GridSearchCV` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)) class to perform cross-validation. You do not need to code cross-validation from scratch, though you are welcome to do so.\n",
    "\n",
    "Here's an example of how to use `GridSearchCV`. Suppose we wanted to experiment with 4 different solvers (numerical methods for optimizing the mode) models for a `LogisticRegression` model `lr_model`. \n",
    "1. We could define a dictionary specifying the hyperparameters and the specific values we want to try out like so: `parameters = {'solver':[{'lbfgs', 'liblinear', 'newton-cg', 'saga']}`.\n",
    "2. Running `grid = GridSearchCV(estimator=lr_model, param_grid=parameters)` would give us a model for each combination of hyperparameters we are testing - in this case, just 4 models.\n",
    "3. We fit each model to some training data `X_train` and `Y_train` using `grid_result = grid.fit(X_train, Y_train)`.\n",
    "4. Indexing into `grid_result.cv_results_` with a particular metric (in this case, `mean_test_score`), we get an array with the scores corresponding to each of the models. `grid_result.cv_results_['mean_test_score']`.\n",
    "Feel free to experiment with other hyperparameters and metrics as well. The documentation is your friend!     \n",
    "       \n",
    "You may use whatever method you prefer to create features, but **you may only use the packages we've imported for you in the cell below or earlier in this notebook**. In addition, **you are only allowed to train logistic regression models**. No decision trees, random forests, k-nearest-neighbors, neural nets, etc. \n",
    "\n",
    "**Note 1:** You may want to use your **validation data** to evaluate your model and get a better sense of how it will perform on the test set. However, you may overfit to your validation set if you try to optimize your validation accuracy too much. Alternatively, you can perform cross-validation on the entire training set.\n",
    "\n",
    "**Note 2:** If you see a `ConvergenceWarning`, increase the maximum number of iterations the model runs for by passing in a parameter, `max_iter`, into `LogisticRegression()`. This should get rid of the warning. For a longer discussion on why this warning appears, you might find [this StackOverflow post](https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter) helpful. Convergence of solvers is not in scope for Data 100, but by understanding what the error messages are saying, you can get some useful context on what to do in these situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 1: Exploratory Data Analysis\n",
    "\n",
    "To decide which features to use when building your model, it is helpful to conduct EDA. Show a visualization you used to select features for your model. \n",
    "\n",
    "Please include:\n",
    "\n",
    "1. A plot showing something meaningful about the data that helped you during feature selection, model selection, or both.\n",
    "2. Two or three sentences describing what you plotted and its implications with respect to your features.\n",
    "\n",
    "You can create as many plots as you want in your feature selection process, but you should select only one for the response question below.\n",
    "\n",
    "**You should not just produce an identical visualization to Question 3 in Project B1.** For this section, we’d like you to go beyond the analysis you performed in Project B1. Choose some plot other than the 1-dimensional distribution of some quantity for spam and ham emails. In particular, do not produce a bar plot of proportions like you created in Question 3 of Project B1. Any other plot is acceptable, **as long as it comes with thoughtful commentary.** Here are some ideas:\n",
    "\n",
    "1. Consider the correlation between multiple features (look up correlation plots and `sns.heatmap` ([documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html))). \n",
    "1. Try to show redundancy in a group of features (e.g., `body` and `html` might co-occur relatively frequently, or you might be able to design a feature that captures all HTML tags and compares them to these). \n",
    "1. Visualize which words have high or low values for helpful statistics.\n",
    "1. Visually depict whether spam emails tend to be wordier (in some sense) than ham emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1a\n",
    "\n",
    "Generate your visualization in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count of Emails')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "filtered_train = train.copy()\n",
    "filtered_train[\"Number of Exlamation Points\"] = train['email'].str.findall(r'!').str.len()\n",
    "\n",
    "\n",
    "filtered_train = filtered_train[filtered_train[\"Number of Exlamation Points\"] <= 11]\n",
    "\n",
    "bins = [0, 3, 5, 9, 12]  \n",
    "labels=[\"0-2\", \"3-4\", \"5-8\", \"9-11\"]\n",
    "\n",
    "filtered_train[\"Exclamation Point Count Bin\"] = pd.cut(\n",
    "    filtered_train[\"Number of Exlamation Points\"], bins=bins, labels=labels, right=True\n",
    ")\n",
    "\n",
    "sns.countplot(data=filtered_train, x=\"Exclamation Point Count Bin\", hue=\"spam\")\n",
    "\n",
    "plt.title(\"Distribution of Emails by Exclamation Point Count (Bin) and Spam Status\")\n",
    "plt.xlabel(\"Number of Exclamation Points (Binned)\")\n",
    "plt.ylabel(\"Count of Emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1b\n",
    "\n",
    "In two to three sentences, describe what you plotted and its implications with respect to your features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows how emails are distributed based on the number of exclamation points and whether they are spam or not. Most emails with 0-2 exclamation points are non-spam, but as the number of exclamation points increases, especially in the 5-8 and 9-11 bins, the proportion of spam emails grows significantly. This pattern suggests that the number of exclamation points could be an important feature for classifying spam emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 2: Building Your Own Model\n",
    "\n",
    "Now that you've explored the data and relevant features through EDA, it's time to build your model! As mentioned earlier, you may use whatever method you prefer to create features, but **you may only use the packages we've imported for you in the cell below or earlier in this notebook**. In addition, **you are only allowed to train logistic regression models**. No decision trees, random forests, k-nearest-neighbors, neural nets, etc. \n",
    "\n",
    "Please consider the ideas mentioned above when choosing features. We have not provided any code to do this, so feel free to create as many cells as you need to tackle this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# You may use any of these to create your features.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    processed_data = data.copy()\n",
    "\n",
    "    processed_data[\"Number of Exclamation Points\"] = data['email'].str.findall(r'!').str.len()\n",
    "    processed_data[\"Number of Capital Letters\"] = data['email'].str.findall(r'[A-Z]').str.len()\n",
    "    processed_data[\"Email Length\"] = data['email'].str.len()\n",
    "    processed_data[\"Number of Links or URLs\"] = data['email'].str.findall(r'\\b(link|url)\\b').str.len()\n",
    "    processed_data[\"Repeated Exclamation Points\"] = data['email'].str.findall(r'!!+').str.len()\n",
    "    processed_data[\"Word Count\"] = data['email'].str.split().str.len()\n",
    "    processed_data[\"Percentage of Capital Letters\"] = (\n",
    "        processed_data[\"Number of Capital Letters\"] / processed_data['email'].str.len()\n",
    "    )\n",
    "    processed_data[\"Contains HTML\"] = data['email'].str.contains(r'<[^>]+>', regex=True).astype(int)\n",
    "    processed_data[\"HTML Proportion\"] = (\n",
    "        data['email'].str.count(r'<[^>]+>') / data['email'].str.len()\n",
    "    )\n",
    "    processed_data[\"Spam Keyword Count\"] = data['email'].str.findall(\n",
    "        r'\\b(free|offer|buy now|win|cash|prize|lowest rates|credit)\\b'\n",
    "    ).str.len()\n",
    "    processed_data[\"Non-ASCII Characters\"] = data['email'].str.count(r'[^\\x00-\\x7F]')\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "features = [\n",
    "    \"Number of Exclamation Points\",\n",
    "    \"Number of Capital Letters\",\n",
    "    \"Email Length\",\n",
    "    \"Number of Links or URLs\",\n",
    "    \"Repeated Exclamation Points\",\n",
    "    \"Word Count\",\n",
    "    \"Percentage of Capital Letters\",\n",
    "    \"Contains HTML\",\n",
    "    \"HTML Proportion\",\n",
    "    \"Spam Keyword Count\",\n",
    "    \"Non-ASCII Characters\"\n",
    "]\n",
    "\n",
    "processed_train = preprocess_data(train)\n",
    "processed_val = preprocess_data(val)\n",
    "processed_test = preprocess_data(test)\n",
    "\n",
    "X_train = processed_train[features]\n",
    "y_train = processed_train[\"spam\"] \n",
    "\n",
    "X_val = processed_val[features]\n",
    "y_val = processed_val[\"spam\"]\n",
    "\n",
    "X_test = processed_test[features] \n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10], \n",
    "    'penalty': ['l1', 'l2'], \n",
    "    'solver': ['liblinear'] \n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=LogisticRegression(max_iter=1000),\n",
    "                    param_grid=param_grid,\n",
    "                    cv=5,\n",
    "                    scoring='accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "y_val_pred_best = best_model.predict(X_val)\n",
    "val_accuracy_best = accuracy_score(y_val, y_val_pred_best)\n",
    "\n",
    "test_predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "# Question 3\n",
    "\n",
    "### Grading Scheme\n",
    "\n",
    "Your grade for this question will be based on your model’s accuracy when making predictions on the training set and your model’s accuracy when making predictions on the test set. The tables below provide scoring guidelines. If your accuracy lies in a particular range, you will receive the number of points associated with that range.\n",
    "\n",
    "**Important**: While your training accuracy can be checked at any time in this notebook, your test accuracy can only be checked by submitting your model’s predictions to Gradescope. **You will only be able to submit your test set predictions to Gradescope up to 4 times per day**. In the case that you are approved for an extension, you are granted 4 more submissions for each day the deadline has been extended. Plan ahead to make sure you have enough time to fine-tune your model! The thresholds are as follows:\n",
    "\n",
    "Points | 5 | 3 | 1.5 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "**Training** Accuracy | 85% and Above | \\[80, 85) | \\[70, 80) | Below 70%\n",
    "\n",
    "Points | 10 | 6 | 3 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "**Testing** Accuracy | 85% and Above | \\[80, 85) | \\[70, 80) | Below 70%\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3a: Train Predictions\n",
    "Assign your predictions for the class of each data point in the training set `train` to `train_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8699587381871423"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = best_model.predict(X_train)\n",
    "\n",
    "training_accuracy = np.mean(train_predictions == train[\"spam\"])\n",
    "training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3a</pre></strong> passed! 🍀</p>"
      ],
      "text/plain": [
       "q3a results: All test cases passed!"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3b: Test Predictions\n",
    "\n",
    "The following code will write your predictions on the test dataset to a CSV file. **You will need to submit this file to the \"Project B2 Test Set Predictions\" assignment on Gradescope to get credit for this question.**\n",
    "\n",
    "Assign your predictions for the class of each datapoint in the test set `test` to a 1-dimensional array called `test_predictions`. **Please make sure you save your predictions to `test_predictions`, as this is how part of your score for this question will be determined.**\n",
    "\n",
    "**Remember that if you've performed transformations or featurization on the training data, you must also perform the same transformations on the test data in order to make predictions.** For example, if you've created features for the words \"drug\" and \"money\" on the training data, you must also extract the same features in order to use `scikit-learn`'s `.predict` method.\n",
    "\n",
    "**Gradescope limits you to 4 submissions per day to meet the threshold.** If you are approved for an extension, you are granted 4 more submissions for each day the deadline has been extended.\n",
    "\n",
    "The provided tests check that your predictions are in the correct format but are worth 0 points in the *Project B2 Coding assignment*. To evaluate your classifier accuracy, you must submit the CSV file to the *Project B2 Test Set Predictions* assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell generates a CSV file with your predictions. **You must submit this CSV file to the \"Project B2 Test Set Predictions\" assignment on Gradescope to get credit for this question.** You can only submit to Gradescope a maximum of 4 times per day, so please use your submissions wisely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n",
    "# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": test['id'], \n",
    "    \"Class\": test_predictions,\n",
    "}, columns=['Id', 'Class'])\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = \"submission_{}.csv\".format(timestamp)\n",
    "submission_df.to_csv(filename, index=False)\n",
    "\n",
    "print('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\n",
    "display(HTML(\"Download your test prediction <a href='\" + filename + \"' download>here</a>.\"))\n",
    "print('You may now upload this CSV file to Gradescope for scoring.')#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Analyzing Your Model\n",
    "\n",
    "Congratulations on completing your model! In the next few questions, we'll ask you to comment on your process for building a successful model and better understand the amount of misclassifications your model makes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "# Question 4\n",
    "\n",
    "Describe the process of improving your model. You should use at least 2-3 sentences each to address the following questions:\n",
    "\n",
    "1. How did you find better features for your model?\n",
    "2. What did you try that worked or didn't work?\n",
    "3. What was surprising in your search for good features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve my model, I focused on features like the frequency of spam keywords, exclamation points, and capital letters, as these helped distinguish spam from non-spam emails. I also tried adding advanced features like HTML tags and character variety, testing them together with simpler ones to see what worked best. Through this iterative process, I found that combining simpler features and scaling the data led to better results. It was surprising to see that not all complex features improved accuracy, which showed me the importance of experimenting with different combinations of features to train my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "# Question 5: ROC Curve\n",
    "\n",
    "In most cases, we won't be able to get 0 false positives and 0 false negatives, so we have to compromise. For example, in the case of cancer screenings, false negatives are comparatively worse than false positives — a false negative means that a patient might not discover that they have cancer until it's too late. In contrast, a patient can receive another screening for a false positive.\n",
    "\n",
    "Recall that logistic regression calculates the probability that an example belongs to a particular class. To classify an example, we say that an email is spam if our classifier gives it $\\ge 0.5$ probability of being spam. However, **we can adjust that cutoff threshold**. We can say that an email is spam only if our classifier gives it $\\ge 0.7$ probability of being spam, for example. This is how we can trade off false positives and false negatives.\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve shows this trade-off for each possible cutoff probability. In the cell below, plot an ROC curve for your final classifier (the one you use to make predictions for Gradescope) on the training data. [Lecture 23](https://ds100.org/fa24/lecture/lec23/) may be helpful.\n",
    "\n",
    "**Hint**: You'll want to use the `.predict_proba` method [(documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba) for your classifier instead of `.predict` to get probabilities instead of binary predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_proba)\n",
    "plt.plot(fpr, tpr, label='ROC Curve')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Diving Deeper\n",
    "\n",
    "So far, we’ve been looking at our model through the lens of accuracy. In the next two questions, we'll dive deeper into the complexities of analyzing our model's performance. In particular, we'll ask you to explore some ambiguous cases that can arise, even within the training data itself, and the consequences of misclassification. You may have already come across some of these cases unknowingly when building your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 6\n",
    "\n",
    "To help you better understand some of the challenges that arise with classification, we've selected three emails from the `train` `DataFrame` and provided them below. Each email highlights a different issue that could arise. Skim through each of the emails below before answering part a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, don't modify it.\n",
    "\n",
    "print(\"spam: \" + str(train.loc[5216][\"spam\"]))\n",
    "print(\"\\nemail:\\n\" + train.loc[5216][\"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, don't modify it.\n",
    "\n",
    "print(\"spam: \" + str(train.loc[36][\"spam\"]))\n",
    "print(\"\\nemail:\\n\" + train.loc[36][\"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, don't modify it.\n",
    "\n",
    "print(\"spam: \" + str(train.loc[1092][\"spam\"]))\n",
    "print(\"\\nemail:\\n\" + train.loc[1092][\"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6a\n",
    "\n",
    "Pick at least **one** of the emails provided above to comment on. How would you classify the email (e.g., spam or ham), and does this align with the classification provided in the training data? What could be a reason someone would disagree with *your* classification of the email? In 2-3 sentences, explain your perspective and potential reasons for disagreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third email about the telecom partnership and phone card promotion is classified as ham in the training data. I would classify it as spam because it includes a promotional offer and repetitive marketing language, which are typical characteristics of spam emails. However, someone might disagree with this classification because it comes from Ryanair which is a reputable source and includes disclaimers and contact information, which could make it seem more legitimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6b\n",
    "\n",
    "As data scientists, we sometimes take the data to be a fixed “ground truth,” establishing the “correct” classification of emails. However, as you might have seen above, some emails can be ambiguous; people may disagree about whether an email is actually spam or ham. How does the ambiguity in our labeled data (spam or ham) affect our understanding of the model's predictions and the way we measure/evaluate our model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambiguity in labeled data can make it harder for the model to learn clear patterns, which affects how well it predicts and how we evaluate it. For example, if one person labels an email as spam while someone else thinks it’s not, the model might pick up on conflicting signals that don’t truly represent spam. This can lead to mistakes, like flagging normal emails as spam or missing actual spam. It also means metrics like accuracy and precision might not fully reflect how well the model works in real-life situations, where people’s opinions on what counts as spam can differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "As a data scientist, we encourage you to think more critically about your data before establishing it as the \"ground truth.\" Whenever you're working on a specific problem, ask yourself:  \n",
    "1. Who “made” the data? Think about all the stages from when it was first generated, collected, and labeled before it ended up in a CSV file.\n",
    "2. What assumptions and biases are inherently present in the data?\n",
    "3. And finally, how does all this affect how you interpret your model’s performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 7\n",
    "\n",
    "In Question 6, we explored the instability present in the “ground truth” and how this affects our evaluation of our model. Now, let's start thinking about your model's interpretability and what that means more broadly for an email classification task. A model is considered interpretable if humans can easily understand the reasoning behind its predictions and classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7a\n",
    "\n",
    "First, let's see if we can understand how our choice of features relates to how a particular email is classified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part i\n",
    "\n",
    "Let’s take a look at the `simple_model` we provided you earlier that uses 5 features. We have provided the code below for ease of reference. You will examine how a particular feature influences how an email is classified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Simple model introduced at the start of this notebook. Just pay attention to the features.\n",
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = words_in_texts(some_words, train['email'])\n",
    "Y_train = np.array(train['spam'])\n",
    "\n",
    "simple_model = LogisticRegression()\n",
    "simple_model.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Pick an email from the training set and assign its index to `email_idx`. Then, find **one** feature used in `simple_model` such that **removing** it changes how that email is classified. Assign this feature to  `feature_to_remove`.\n",
    "\n",
    "**Hint**: We suggest starting with finding spam emails that contain the features in our model. All the features in our simple model relate to spam emails, thus it is easier to find a spam email + remove a feature to get it to flip classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this cell for scratch work when determining `email_idx`\n",
    "train[\"Spam Keyword\"] = train['email'].str.findall(\n",
    "        r'\\b(drug|bank|prescription|memo|private)\\b'\n",
    "    )\n",
    "non_empty_spam_keyword = train[train[\"Spam Keyword\"].apply(lambda x: len(x) > 0)]\n",
    "non_empty_spam_keyword.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "email_idx = 714\n",
    "\n",
    "prob_spam = simple_model.predict_proba(X_train)[:, 1]\n",
    "initial_prob = prob_spam[email_idx]\n",
    "initial_class = \"spam\" if np.round(initial_prob) else \"ham\"\n",
    "print(f\"\\nPredicted probability of being spam: {np.round(initial_prob*100, 2)}%\")\n",
    "print(\"\\nEmail:\\n\" + train.loc[email_idx][\"email\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_to_remove = \"bank\"\n",
    "\n",
    "changed_words = some_words.copy()\n",
    "changed_words.remove(feature_to_remove)\n",
    "\n",
    "changed_model = LogisticRegression()\n",
    "X_changed = words_in_texts(changed_words, train['email'])\n",
    "y = train['spam']\n",
    "changed_model.fit(X_changed, y)\n",
    "changed_prob = changed_model.predict_proba(X_changed[[email_idx]])[:,1][0]\n",
    "changed_class = \"spam\" if np.round(changed_prob) else \"ham\"\n",
    "\n",
    "print(f\"Initially classified as {initial_class} (Probability: {np.round(initial_prob*100, 2)}%)\")\n",
    "print(f\"Now classified as {changed_class} (Probability: {np.round(changed_prob*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Part ii\n",
    "\n",
    "Please provide below the index of the email that you removed (`email_idx`). Additionally, in 2-3 sentences, explain why you think the feature you chose to remove changed how your email was classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed the email at index 714 because the keyword \"bank\" significantly influenced its classification as spam. The email is an informational newsletter about banking practices and advice, with no promotional or malicious intent, making the context clearly non-spam. Removing \"bank\" as a feature reduced the model's reliance on financial keywords, leading to a reclassification as ham. This demonstrates the importance of considering the email's context when selecting features, as certain keywords can carry different meanings depending on how they are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 7b\n",
    "\n",
    "Now, let's say that instead of working with a small model containing 50-100 features, you're working with a much larger, more accurate model containing 1000 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Part i\n",
    "In this context, do you think you could easily find a feature that could change an email's classification as you did in part a)? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a model with 1000 features, it would be much harder to find one feature that drastically changes an email’s classification. This is because larger models distribute predictive power across many features, so no single one carries as much weight. While removing one feature might still have some impact, its influence would be diluted by the presence of other features capturing similar patterns or supporting information. As a result, the model's predictions would probably remain consistent even without that specific feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Part ii \n",
    "Would you expect this new model to be more or less interpretable than `simple_model`?\n",
    "\n",
    "**Note**: A model is considered interpretable if you can easily understand the reasoning behind its predictions and classifications. For example, the model we saw in part a), `simple_model`, is considered interpretable as we can identify which features contribute to an email's classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model with 1000 features would be less interpretable than the simple model. In the simple model, it’s easy to pinpoint which features are driving the predictions because the feature set is small and manageable. However, with a much larger model, the reasoning behind predictions becomes harder to trace since the predictive power is spread across so many features. This complexity makes it challenging to identify the specific contributions of individual features to the model's classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 7c\n",
    "\n",
    "Now, imagine you’re a data scientist at Meta, developing a text classification model to decide whether to remove certain posts / comments on Facebook. In particular, you’re primarily working on moderating the following categories of content:\n",
    "* Hate speech\n",
    "* Misinformation \n",
    "* Violence and incitement\n",
    "\n",
    "Pick one of these types of content to focus on (or if you have another type you’d like to focus on, feel free to comment on that!). What content would fall under the category you’ve chosen? Refer to Facebook’s [Community Standards](https://transparency.fb.com/policies/community-standards/), which outline what is and isn’t allowed on Facebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would focus on moderating hate speech because it involves content that targets people based on characteristics like race, ethnicity, religion, gender, or sexual orientation. This includes slurs, harmful stereotypes, and direct attacks or threats against these groups. According to Facebook's Community Standards, such content is not allowed because it violates dignity and can sometimes incite harm. By moderating hate speech, we help ensure the platform remains a safe, comfortable, and respectful place for everyone to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 7d\n",
    "\n",
    "What are the stakes of misclassifying a post in the context of a social media platform? Comment on what a false positive and false negative means for the category of content you’ve chosen (hate speech, misinformation, or violence and incitement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of moderating hate speech, misclassifying content can have serious consequences. A false positive means removing a post that isn’t actually hate speech, which could unfairly silence someone’s voice or limit their ability to express themselves. On the other hand, a false negative lets real hate speech stay on the platform, which can harm individuals or communities by spreading hostility or encouraging violence. Both mistakes can damage the platform’s trust and safety, so it’s important to carefully balance these risks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 7e\n",
    "\n",
    "As a data scientist, why might having an interpretable model be useful when moderating content online?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having an interpretable model is essential for moderating content online because it allows data scientists to understand the reasoning behind specific classifications. This transparency is crucial for identifying and addressing potential biases in the model, making sure that decision-making is equitable. It also helps explain moderation outcomes to users, building trust and accountability for both ends—the users and the data scientists, developers, or engineers responsible for maintaining the system. Furthermore, an interpretable model is useful for the iterative process of developing and improving the model by making it easier to pinpoint which features need adjustment or refinement as it is inevitable that the nature of harmful content evolves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "As you explored throughout this question, interpretability is incredibly important. However, it is equally important to note that interpretability on its own isn’t a fix to all the problems that may arise when moderating content or when building a model more generally. As we touched on in Project A2, these models don’t operate in a vacuum; they exist in a wider sociotechnical system. Everything from the data used to train these models to the metrics we choose to evaluate our models builds on that notion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## The pets of Data100 congratulate you for finishing Project B2 (the last major assignment)!\n",
    "\n",
    "<div align=\"middle\">\n",
    "    <table style=\"width:75%\">\n",
    "      <tr align=\"center\">\n",
    "        <td><img src=\"images/IMG_2792.jpg\" align=\"middle\" width=\"325vw\"/>\n",
    "        <td><img src=\"images/_DSC9613.jpg\" align=\"middle\" width=\"335vw\"/>\n",
    "        <td><img src=\"images/IMG_2797.jpg\" align=\"middle\" width=\"325vw\"/>\n",
    "      </tr>\n",
    "      <tr align=\"center\">\n",
    "        <td><img src=\"images/IMG_5768.jpg\" align=\"middle\" width=\"325vw\"/>\n",
    "        <td><img src=\"images/IMG_2485.jpg\" align=\"middle\" width=\"325vw\"/>\n",
    "        <td><img src=\"images/IMG_5878.jpg\" align=\"middle\" width=\"325vw\"/>\n",
    "      </tr>\n",
    "      <tr align=\"center\">\n",
    "        <td><img src=\"images/IMG_8790.jpg\" align=\"middle\" width=\"325vw\"/>\n",
    "        <td><img src=\"images/IMG_6077.jpeg\" align=\"middle\" width=\"325vw\"/>\n",
    "        <td><img src=\"images/IMG_9524.jpg\" align=\"middle\" width=\"325vw\"/>\n",
    "      </tr>\n",
    "    </table>\n",
    "  </div>\n",
    "\n",
    "### Course Content Feedback\n",
    "\n",
    "If you have any feedback about this assignment or about any of our other weekly, weekly assignments, lectures, or discussions, please fill out the [Course Content Feedback Form](https://docs.google.com/forms/d/e/1FAIpQLSdpKA_E3b7PGqKSRqBUgSebb9bVFhRwRBv1ueisGsnKFkZkYg/viewform). Your input is valuable in helping us improve the quality and relevance of our content to better meet your needs and expectations!\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Below, you will see a cell. Running this cell will automatically generate a zip file with your autograded answers. Once you submit this file to the Project B2 Coding assignment on Gradescope, Gradescope will automatically submit a PDF file with your written answers to the Project B2 Written assignment. If you run into any issues when running this cell, feel free to check this [section](https://ds100.org/debugging-guide/autograder_gradescope/autograder_gradescope.html#why-does-grader.exportrun_teststrue-fail-if-all-previous-tests-passed) in the Data 100 Debugging Guide.\n",
    "\n",
    "If there are issues with automatically generating the PDF, you can try downloading the notebook as a PDF by clicking on `File -> Save and Export Notebook As... -> PDF`. If that doesn't work either, you can manually take screenshots of your answers to the manually graded questions and submit those. \n",
    "\n",
    "**Please make sure you submit the following to the right assignments:**\n",
    "\n",
    "* **Project B2 Coding:** Submit the zip file generated by using the `grader.export()` cell provided below.\n",
    "* **Project B2 Written:** Gradescope will automatically submit the PDF from the zip file submitted earlier. You do not need to submit anything to this assignment yourself, but *please check that the submission went through properly and that all plots rendered correctly*.\n",
    "* **Project B2 Test Set Predictions:** Submit the CSV file generated in `q3b`.\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements and that everything was generated and submitted correctly. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "otter": {
   "OK_FORMAT": true,
   "require_no_pdf_confirmation": true,
   "tests": {
    "q3a": {
     "name": "q3a",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'sklearn.feature_extraction.text' not in sys.modules.keys()\n>>> bool(training_accuracy >= 0.7)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> assert 'sklearn.feature_extraction.text' not in sys.modules.keys()\n>>> bool(training_accuracy >= 0.8)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> assert 'sklearn.feature_extraction.text' not in sys.modules.keys()\n>>> bool(training_accuracy >= 0.84)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'sklearn.feature_extraction.text' not in sys.modules.keys()\n>>> bool(isinstance(test_predictions, np.ndarray))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 'sklearn.feature_extraction.text' not in sys.modules.keys()\n>>> bool(np.array_equal(np.unique(test_predictions), np.array([0, 1])))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 'sklearn.feature_extraction.text' not in sys.modules.keys()\n>>> bool(len(test_predictions) == 1000)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7ai": {
     "name": "q7ai",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert simple_model.n_features_in_ == changed_model.n_features_in_ + 1\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert changed_class != initial_class\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
